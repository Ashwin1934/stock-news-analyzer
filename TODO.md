- Look into Prom / Grafana monitoring of the containers as well as CPU / GPU statistics.
#### 1/28/26
Need to focus on implementation, what libraries to use. Should the model be downloaded onto the server? Or fetched over the internet via pytorch? Figure out what to monitor and track.
Inference request time, model load time, CPU/GPU monitoring via prometheus and grafana.